import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:speech_to_text/speech_to_text.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:record/record.dart';

class AudioService {
  final SpeechToText _speechToText = SpeechToText();
  final AudioRecorder _audioRecorder = AudioRecorder();

  StreamController<String>? _speechResultController;
  StreamController<bool>? _listeningController;
  StreamController<double>? _soundLevelController;

  bool _isInitialized = false;
  bool _isListening = false;
  Timer? _soundLevelTimer;

  Stream<String> get speechResults => _speechResultController!.stream;
  Stream<bool> get listeningStatus => _listeningController!.stream;
  Stream<double> get soundLevel => _soundLevelController!.stream;

  bool get isListening => _isListening;
  bool get isInitialized => _isInitialized;

  Future<void> initialize() async {
    try {
      _speechResultController = StreamController<String>.broadcast();
      _listeningController = StreamController<bool>.broadcast();
      _soundLevelController = StreamController<double>.broadcast();

      // Request permissions
      await _requestPermissions();

      // Initialize speech to text
      _isInitialized = await _speechToText.initialize(
        onError: _onSpeechError,
        onStatus: _onSpeechStatus,
      );

      if (kDebugMode) {
        print('AudioService initialized: $_isInitialized');
        if (_isInitialized) {
          // æª¢æŸ¥å¯ç”¨çš„èªè¨€
          final locales = await availableLocales;
          print('Available speech locales: $locales');
        }
      }
    } catch (e) {
      if (kDebugMode) {
        print('AudioService initialization error: $e');
      }
    }
  }

  Future<void> _requestPermissions() async {
    print('ğŸ”’ Checking microphone permission...');

    // å…ˆæª¢æŸ¥ç•¶å‰æ¬Šé™ç‹€æ…‹
    final currentStatus = await Permission.microphone.status;
    print('Current microphone permission status: $currentStatus');

    if (currentStatus == PermissionStatus.granted) {
      print('âœ… Microphone permission already granted');
      return;
    }

    // å¦‚æœæœªæˆæ¬Šï¼Œè«‹æ±‚æ¬Šé™
    print('ğŸ”’ Requesting microphone permission...');
    final micPermission = await Permission.microphone.request();

    print('Microphone permission result: $micPermission');

    if (micPermission != PermissionStatus.granted) {
      if (micPermission == PermissionStatus.permanentlyDenied) {
        throw Exception(
            'Microphone permission permanently denied. Please enable in Settings.');
      } else {
        throw Exception('Microphone permission not granted: $micPermission');
      }
    }

    print('âœ… Microphone permission granted');
  }

  Future<void> startListening({
    String localeId = 'en-US',
    bool partialResults = true,
    bool realTimeMode = false,
  }) async {
    if (!_isInitialized || _isListening) return;

    // ä¿å­˜åƒæ•¸ä¾›é‡æ–°å•Ÿå‹•ä½¿ç”¨
    _lastLocaleId = localeId;
    _lastPartialResults = partialResults;
    _lastRealTimeMode = realTimeMode;
    _shouldKeepListening = realTimeMode; // å¯¦æ™‚æ¨¡å¼ä¸‹ä¿æŒæŒçºŒç›£è½

    try {
      if (kDebugMode) {
        print(
            'Starting speech recognition with locale: $localeId, realTime: $realTimeMode, keepListening: $_shouldKeepListening');
        print('Available locales: ${await availableLocales}');
      }

      await _startListeningInternal(
        localeId: localeId,
        partialResults: partialResults,
        realTimeMode: realTimeMode,
      );
    } catch (e) {
      if (kDebugMode) {
        print('Error starting speech recognition: $e');
      }
    }
  }

  Future<void> stopListening() async {
    // åœæ­¢æŒçºŒç›£è½æ¨¡å¼
    _shouldKeepListening = false;

    if (!_isListening) return;

    try {
      await _speechToText.stop();
      _isListening = false;
      _listeningController?.add(false);

      // åœæ­¢éŸ³é‡ç´šåˆ¥ç›£æ§
      _stopSoundLevelMonitoring();

      if (kDebugMode) {
        print('Stopped listening (keepListening: $_shouldKeepListening)');
      }
    } catch (e) {
      if (kDebugMode) {
        print('Error stopping speech recognition: $e');
      }
    }
  }

  void _onSpeechResult(result) {
    final words = result.recognizedWords;
    final isFinal = result.finalResult;

    if (kDebugMode) {
      print(
          'Speech result received: "$words" (final: $isFinal, confidence: ${result.confidence})');
    }

    if (words.isNotEmpty) {
      _speechResultController?.add(words);
    } else {
      if (kDebugMode) {
        print('Empty speech result received');
      }
    }
  }

  void _onSpeechError(error) {
    if (kDebugMode) {
      print('Speech error: $error');
      print('Error type: ${error.runtimeType}');
      print('Is listening: $_isListening');
      print('Should keep listening: $_shouldKeepListening');
    }

    final errorMsg = error.toString();

    // åœ¨å¯¦æ™‚æ¨¡å¼ä¸‹ï¼Œæ°¸é ä¸è¦å› ç‚ºéŒ¯èª¤è€Œåœæ­¢ç›£è½
    if (_shouldKeepListening) {
      print('Real-time mode: Ignoring error and continuing to listen...');
      return;
    }

    // å¦‚æœæ˜¯ "no match" éŒ¯èª¤ï¼Œé€™åªæ˜¯è¡¨ç¤ºæ²’æœ‰æª¢æ¸¬åˆ°èªéŸ³ï¼Œä¸æ˜¯çœŸæ­£çš„éŒ¯èª¤
    if (errorMsg.contains('error_no_match')) {
      print('No speech detected, but continuing to listen...');
      // åœ¨å¯¦æ™‚æ¨¡å¼ä¸‹ï¼Œå³ä½¿æ˜¯ no_match ä¹Ÿè¦é‡æ–°å•Ÿå‹•
      if (_shouldKeepListening) {
        print('ğŸ”„ Restarting after no_match error in real-time mode...');
        _isListening = false;
        _restartListeningIfNeeded();
      }
      return;
    }

    // å¦‚æœæ˜¯è¶…æ™‚éŒ¯èª¤ï¼Œå˜—è©¦é‡æ–°é–‹å§‹ç›£è½
    if (errorMsg.contains('timeout') ||
        errorMsg.contains('error_speech_timeout')) {
      print('Speech timeout detected - continuing to listen...');
      return;
    }

    // åªåœ¨éå¯¦æ™‚æ¨¡å¼ä¸‹æ‰åœæ­¢ç›£è½
    print('Non-real-time mode: Speech error detected, stopping listening');
    _isListening = false;
    _listeningController?.add(false);
    _stopSoundLevelMonitoring();
  }

  void _onSpeechStatus(status) {
    if (kDebugMode) {
      print(
          'Speech status: $status (shouldKeepListening: $_shouldKeepListening, isListening: $_isListening)');
    }

    // åœ¨å¯¦æ™‚æ¨¡å¼ä¸‹ï¼Œå®Œå…¨å¿½ç•¥ç‹€æ…‹è®ŠåŒ–ï¼Œä¿æŒç›£è½
    if (_shouldKeepListening) {
      if (status == 'done' || status == 'notListening') {
        print('Real-time mode: Speech session ended, scheduling restart...');

        // è¨­ç½®ç›£è½ç‹€æ…‹ç‚ºfalseï¼Œä½†ä¸åœæ­¢éŸ³é‡ç›£æ§
        _isListening = false;

        // ç«‹å³è§¸ç™¼é‡æ–°å•Ÿå‹•
        print('ğŸš€ Triggering immediate restart from status change...');
        _restartListeningIfNeeded();
      } else if (status == 'listening') {
        print('âœ… Speech recognition listening state confirmed');
        _isListening = true;
        _listeningController?.add(true);
      }
      return;
    }

    // éå¯¦æ™‚æ¨¡å¼ä¸‹çš„æ­£å¸¸è™•ç†
    if (status == 'done' || status == 'notListening') {
      _isListening = false;
      _listeningController?.add(false);
      _stopSoundLevelMonitoring();
    }
  }

  bool _shouldKeepListening = false;
  String? _lastLocaleId;
  bool _lastPartialResults = true;
  bool _lastRealTimeMode = false;

  Timer? _restartTimer;

  void _restartListeningIfNeeded() {
    if (_shouldKeepListening && _lastLocaleId != null) {
      print('ğŸ”„ Scheduling auto-restart of speech recognition...');

      // å–æ¶ˆä»»ä½•ç¾æœ‰çš„é‡æ–°å•Ÿå‹•è¨ˆæ™‚å™¨
      _restartTimer?.cancel();

      // ç«‹å³é‡æ–°å•Ÿå‹•
      _restartTimer = Timer(Duration(milliseconds: 100), () async {
        if (_shouldKeepListening) {
          try {
            print('ğŸ”„ Auto-restarting speech recognition now...');

            // ç¢ºä¿å…ˆåœæ­¢ä»»ä½•ç¾æœ‰çš„ç›£è½
            try {
              await _speechToText.stop();
            } catch (e) {
              print('Stop error (ignored): $e');
            }

            _isListening = false;

            // é‡æ–°å•Ÿå‹•
            await _startListeningInternal(
              localeId: _lastLocaleId!,
              partialResults: _lastPartialResults,
              realTimeMode: _lastRealTimeMode,
            );

            print('âœ… Speech recognition restarted successfully');
          } catch (e) {
            print('âŒ Error restarting speech recognition: $e');
            // å¦‚æœå¤±æ•—ï¼ŒçŸ­æš«å»¶é²å¾Œå†æ¬¡å˜—è©¦
            Future.delayed(Duration(milliseconds: 500), () {
              if (_shouldKeepListening) {
                _restartListeningIfNeeded();
              }
            });
          }
        }
      });
    }
  }

  Future<void> _startListeningInternal({
    required String localeId,
    required bool partialResults,
    required bool realTimeMode,
  }) async {
    if (realTimeMode) {
      // å¯¦æ™‚æ¨¡å¼ï¼šç„¡é™ç›£è½ï¼Œä¸è¨­å®šæ™‚é–“é™åˆ¶
      await _speechToText.listen(
        onResult: _onSpeechResult,
        localeId: localeId,
        partialResults: partialResults,
        listenMode: ListenMode.search, // æœç´¢æ¨¡å¼ï¼ŒæŒçºŒç›£è½
        cancelOnError: false, // ä¸è¦å› ç‚ºéŒ¯èª¤å°±å–æ¶ˆ
        // ä¸è¨­å®š listenFor å’Œ pauseForï¼Œè®“å®ƒæŒçºŒç›£è½
      );
    } else {
      // æ­£å¸¸æ¨¡å¼ï¼šä¿æŒåŸä¾†çš„è¨­å®š
      await _speechToText.listen(
        onResult: _onSpeechResult,
        localeId: localeId,
        partialResults: partialResults,
        listenMode: ListenMode.confirmation,
        cancelOnError: false,
        listenFor: const Duration(seconds: 120),
        pauseFor: const Duration(seconds: 15),
      );
    }

    _isListening = true;
    _listeningController?.add(true);

    // é–‹å§‹éŸ³é‡ç´šåˆ¥ç›£æ§
    _startSoundLevelMonitoring();

    if (kDebugMode) {
      print(
          'Started listening in ${realTimeMode ? "real-time" : "standard"} mode...');
    }
  }

  Future<List<String>> get availableLocales async {
    if (!_isInitialized) return ['en-US', 'zh-CN', 'ja-JP'];
    try {
      final locales = await _speechToText.locales();
      final localeIds = locales.map((locale) => locale.localeId).toList();

      if (kDebugMode) {
        print('Available speech recognition locales: $localeIds');
        print('Japanese support: ${localeIds.any((id) => id.contains('ja'))}');
      }

      return localeIds;
    } catch (e) {
      if (kDebugMode) {
        print('Error getting available locales: $e');
      }
      return ['en-US', 'zh-CN', 'ja-JP']; // é è¨­æ”¯æ´çš„èªè¨€
    }
  }

  void _startSoundLevelMonitoring() {
    _soundLevelTimer?.cancel();
    _soundLevelTimer =
        Timer.periodic(const Duration(milliseconds: 100), (timer) {
      if (_isListening) {
        // å¦‚æœ speech_to_text æä¾›éŸ³é‡ç´šåˆ¥ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨å®ƒ
        // å¦å‰‡æˆ‘å€‘æ¨¡æ“¬ä¸€å€‹åŸºæ–¼éš¨æ©Ÿå€¼çš„éŸ³é‡ç´šåˆ¥
        double soundLevel = 0.0;

        // æª¢æŸ¥æ˜¯å¦æœ‰å¯¦éš›çš„éŸ³é‡ç´šåˆ¥ï¼ˆspeech_to_text 6.x+ ç‰ˆæœ¬æ”¯æ´ï¼‰
        if (_speechToText.hasError == false && _isListening) {
          // æ¨¡æ“¬éŸ³é‡ç´šåˆ¥ - åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™å°‡ä¾†è‡ªéº¥å…‹é¢¨
          soundLevel = (0.1 +
              (DateTime.now().millisecondsSinceEpoch % 1000) / 1000.0 * 0.8);
        }

        _soundLevelController?.add(soundLevel);
      }
    });
  }

  void _stopSoundLevelMonitoring() {
    _soundLevelTimer?.cancel();
    _soundLevelTimer = null;
    _soundLevelController?.add(0.0); // é‡ç½®éŸ³é‡ç‚º0
  }

  void dispose() {
    _shouldKeepListening = false;
    _restartTimer?.cancel();
    _speechResultController?.close();
    _listeningController?.close();
    _soundLevelController?.close();
    _soundLevelTimer?.cancel();
    _speechToText.cancel();
  }
}
